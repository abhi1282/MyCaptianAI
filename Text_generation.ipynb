{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO09xZuRb5/wGp3g4WUEYE2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhi1282/MyCaptianAI/blob/main/Text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5jOaHILQXJh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_words(input):\n",
        "  input = input.lower()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(input)\n",
        "  filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
        "  return \" \".join(filtered)\n",
        "\n",
        "processed_inputs = tokenize_words(file)"
      ],
      "metadata": {
        "id": "dmTEdFAU9fvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(processed_inputs)))\n",
        "char_to_num = dict((c, i) for i, c in enumerate(chars))\n"
      ],
      "metadata": {
        "id": "bKnWjxB09x2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_len = len(processed_inputs)\n",
        "vocab_len = len(chars)\n",
        "print(\"Total number of characters:\", input_len)\n",
        "print(\"Total vocab:\", vocab_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgN0lL66_Mxe",
        "outputId": "9668bd0a-14b9-4b45-b3d6-c2c2365fe1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of characters: 269566\n",
            "Total vocab: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = 100\n",
        "x_data = []\n",
        "y_data = []"
      ],
      "metadata": {
        "id": "gG-BZvNk_jJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, input_len - seq_len, 1):\n",
        "  in_seq = processed_inputs[i:i + seq_len]\n",
        "  out_seq = processed_inputs[i + seq_len]\n",
        "  x_data.append([char_to_num[char] for char in in_seq])\n",
        "  y_data.append(char_to_num[out_seq])\n",
        "\n",
        "n_patterns = len(x_data)\n",
        "print(\"Total Patterns:\", n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66exmyXe_nu8",
        "outputId": "2291caa8-6fca-4cb8-a9b6-5a57b9744d9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns: 269466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = numpy.reshape(x_data, (n_patterns, seq_len, 1))\n",
        "X = X/float(vocab_len)"
      ],
      "metadata": {
        "id": "En0m8RXh_tPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y_data)"
      ],
      "metadata": {
        "id": "X3dTgW4N_w6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1],activation = 'softmax'))"
      ],
      "metadata": {
        "id": "K9M_sRcP_4Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "NN5NbEuPCc_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = \"model_weights_saved.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "metadata": {
        "id": "Og-qS4r8Cobz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=4, batch_size=256, callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmlc2vBAC0zf",
        "outputId": "89728aa6-7546-4b3c-cba2-bb046dbb2666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1052/1053 [============================>.] - ETA: 0s - loss: 2.6776\n",
            "Epoch 1: loss improved from inf to 2.67758, saving model to model_weights_saved.hdf5\n",
            "1053/1053 [==============================] - 70s 66ms/step - loss: 2.6776\n",
            "Epoch 2/4\n",
            "   2/1053 [..............................] - ETA: 1:13 - loss: 2.4433"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1053/1053 [==============================] - ETA: 0s - loss: 2.4643\n",
            "Epoch 2: loss improved from 2.67758 to 2.46434, saving model to model_weights_saved.hdf5\n",
            "1053/1053 [==============================] - 71s 67ms/step - loss: 2.4643\n",
            "Epoch 3/4\n",
            "1052/1053 [============================>.] - ETA: 0s - loss: 2.3141\n",
            "Epoch 3: loss improved from 2.46434 to 2.31402, saving model to model_weights_saved.hdf5\n",
            "1053/1053 [==============================] - 71s 68ms/step - loss: 2.3140\n",
            "Epoch 4/4\n",
            "1052/1053 [============================>.] - ETA: 0s - loss: 2.1983\n",
            "Epoch 4: loss improved from 2.31402 to 2.19823, saving model to model_weights_saved.hdf5\n",
            "1053/1053 [==============================] - 71s 67ms/step - loss: 2.1982\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c04358fa740>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"model_weights_saved.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "12DdoAGYDBQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "CySZ3ZStFPs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = numpy.random.randint(0, len(x_data) - 1)\n",
        "pattern = x_data[start]\n",
        "print(\"Random Seed:\")\n",
        "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dizLmrqzFWU5",
        "outputId": "b3fc598b-45d5-4ad5-a9c4-43f0e06e3e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Seed:\n",
            "\" tzerland crept along shores rhine among willow islands summits hills dwelt many months heaths englan \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1000):\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  x = x/float(vocab_len)\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  index = numpy.argmax(prediction)\n",
        "  result = num_to_char[index]\n",
        "  seq_in = [num_to_char[value] for value in pattern]\n",
        "  sys.stdout.write(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CvM4ATurFmUy",
        "outputId": "374c5117-2c73-4ae5-8d81-b01960ec9021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears sears se"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "leJJntwXGBpG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}